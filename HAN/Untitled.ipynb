{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word_Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size=1000, embed_dim=100, seq_length=50, gru_dim=100):\n",
    "        super(Word_Encoder, self).__init__()\n",
    "        self.word_embedding = tf.keras.layers.Embedding(vocab_size, embed_dim,\n",
    "                                                       mask_zero=True, input_length=seq_length)\n",
    "        self.bidirectional_encoder = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=gru_dim))\n",
    "        #TODO: decided output dim of MLP layer\n",
    "        self.MLP = tf.keras.layers.Dense(units=embed_dim, use_bias=True)\n",
    "        self.attention = tf.keras.layers.Attention(use_scale=True)\n",
    "    def call(self, tokenized_sentence):\n",
    "        embedding = self.word_embedding(tokenized_sentence)\n",
    "        embedding = self.bidirectional_encoder(embedding)\n",
    "        embedding = self.MLP(embedding)\n",
    "        embedding = self.attention([embedding, embedding, embedding])\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tf.constant([[1,2,0],[3,2,1]])\n",
    "word_encoder = Word_Encoder()\n",
    "output = word_encoder(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2146, shape=(2, 100), dtype=float32, numpy=\n",
       "array([[-1.42459795e-02,  1.57025196e-02,  7.03833881e-04,\n",
       "        -4.58400231e-03,  1.06078591e-02, -6.51860330e-03,\n",
       "         1.13762673e-02,  6.02916023e-03,  5.65430964e-04,\n",
       "         2.42254534e-03,  4.00782796e-03,  7.29071908e-03,\n",
       "        -1.18857231e-02,  6.75317366e-04,  1.65610071e-02,\n",
       "         5.11040445e-03,  1.07086860e-02, -6.67967554e-03,\n",
       "        -5.50592458e-03, -1.40445931e-02, -2.04944592e-02,\n",
       "         1.63095119e-05, -9.14411992e-03, -1.00131920e-02,\n",
       "        -3.39514436e-03, -1.81542512e-03,  1.00647081e-02,\n",
       "        -1.81859042e-02,  1.40123004e-02, -5.36621781e-03,\n",
       "         1.22716622e-02,  9.21469368e-03, -3.36887613e-02,\n",
       "        -8.26077722e-03,  3.67715582e-03,  6.70440379e-04,\n",
       "         1.51558174e-02,  1.55868160e-03, -7.94125441e-03,\n",
       "        -2.25803927e-02,  5.70491049e-03, -8.89782421e-03,\n",
       "        -7.69106532e-03, -2.39367802e-02, -6.85686106e-03,\n",
       "        -1.65077820e-02,  2.49749850e-02,  1.24909114e-02,\n",
       "         1.14129647e-03, -1.67790037e-02, -1.87387634e-02,\n",
       "        -1.25281792e-02, -8.59226659e-03, -1.40237305e-02,\n",
       "         7.28165905e-04,  1.16004478e-02,  9.94032994e-03,\n",
       "         1.03103472e-02, -1.35357864e-02, -7.53539323e-04,\n",
       "         2.61755977e-02,  1.19457794e-02, -5.76155540e-03,\n",
       "         9.00215842e-03, -1.44102192e-03,  7.52312597e-03,\n",
       "         3.76551715e-03,  1.05435988e-02,  1.32147586e-02,\n",
       "        -3.25324154e-03, -2.16163346e-03,  1.47455949e-02,\n",
       "        -8.29189830e-03, -2.72278115e-03, -9.39192623e-03,\n",
       "         4.43745032e-03, -1.43354945e-03,  3.94023117e-03,\n",
       "        -6.67964062e-03, -8.97896104e-03, -1.25762755e-02,\n",
       "         1.48505839e-02,  1.20601552e-02,  1.25801703e-02,\n",
       "         7.59742688e-03,  2.27646413e-03, -3.94865917e-03,\n",
       "        -1.17935874e-02, -1.17972149e-02, -1.06877536e-02,\n",
       "        -2.24642619e-03, -3.36348289e-03, -6.01464184e-03,\n",
       "        -1.06355399e-02,  1.17982160e-02, -1.91261759e-03,\n",
       "         3.27661238e-03,  7.85600394e-03, -5.82083594e-03,\n",
       "         7.61493808e-03],\n",
       "       [-1.42981289e-02,  1.56830028e-02,  7.48528866e-04,\n",
       "        -4.48722253e-03,  1.06091732e-02, -6.57140603e-03,\n",
       "         1.14266677e-02,  6.06584456e-03,  5.65246155e-04,\n",
       "         2.45022215e-03,  4.01502335e-03,  7.31256558e-03,\n",
       "        -1.19609460e-02,  7.12298846e-04,  1.66272018e-02,\n",
       "         5.10340463e-03,  1.07158022e-02, -6.57980889e-03,\n",
       "        -5.49250236e-03, -1.40037751e-02, -2.05565281e-02,\n",
       "         2.91961842e-05, -9.21908114e-03, -9.98924766e-03,\n",
       "        -3.42848781e-03, -1.86796149e-03,  9.99734178e-03,\n",
       "        -1.81336254e-02,  1.39298961e-02, -5.43629052e-03,\n",
       "         1.23183923e-02,  9.15441941e-03, -3.35891023e-02,\n",
       "        -8.23969580e-03,  3.71074490e-03,  6.85168081e-04,\n",
       "         1.51346624e-02,  1.55698764e-03, -7.91912153e-03,\n",
       "        -2.25450173e-02,  5.76102408e-03, -8.83528031e-03,\n",
       "        -7.69373914e-03, -2.38439124e-02, -6.79337513e-03,\n",
       "        -1.65379401e-02,  2.49815211e-02,  1.24904923e-02,\n",
       "         1.12428179e-03, -1.67957991e-02, -1.87829174e-02,\n",
       "        -1.25122629e-02, -8.53400398e-03, -1.40819112e-02,\n",
       "         6.43313688e-04,  1.16659328e-02,  9.93904658e-03,\n",
       "         1.03268903e-02, -1.36138592e-02, -6.86765590e-04,\n",
       "         2.62570139e-02,  1.18794590e-02, -5.75601868e-03,\n",
       "         8.93655233e-03, -1.43446040e-03,  7.49688502e-03,\n",
       "         3.77799268e-03,  1.06223812e-02,  1.32303918e-02,\n",
       "        -3.23371287e-03, -2.21260567e-03,  1.47533538e-02,\n",
       "        -8.27847049e-03, -2.70471280e-03, -9.37650260e-03,\n",
       "         4.48639691e-03, -1.44639309e-03,  3.91296949e-03,\n",
       "        -6.70585455e-03, -8.96639470e-03, -1.25686284e-02,\n",
       "         1.47636523e-02,  1.20048625e-02,  1.26337325e-02,\n",
       "         7.52001069e-03,  2.20010360e-03, -4.05846164e-03,\n",
       "        -1.17804045e-02, -1.17954332e-02, -1.06828678e-02,\n",
       "        -2.25122971e-03, -3.47273448e-03, -6.07064692e-03,\n",
       "        -1.06574148e-02,  1.17649734e-02, -1.94233924e-03,\n",
       "         3.28515563e-03,  7.87879527e-03, -5.84266149e-03,\n",
       "         7.56510440e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(attention, encoded_words):\n",
    "    attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
