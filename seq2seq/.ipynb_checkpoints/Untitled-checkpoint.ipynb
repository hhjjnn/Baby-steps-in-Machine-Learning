{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je suis en fait plutot flattee .', 'i m actually kind of flattered .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model: encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    # input shape: (B, seq length)\n",
    "    # hidden shape: (B, hidden_size)\n",
    "    # outputs shape: (B, sequence length, hidden_size)\n",
    "    def forward(self, inputs, hidden):\n",
    "        embedded = self.embedding(inputs).view(1, -1, self.hidden_size)\n",
    "        hidden = self.initHidden()\n",
    "        outputs, last_hidden = self.gru(embedded, hidden)\n",
    "        return outputs, last_hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, device):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device=device\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # input shape: (B, seq length)\n",
    "    # embedded shape: (B, seq length, hidden size)\n",
    "    # outputs shape: (B, seq length, hidden size)\n",
    "    def forward(self, inputs, hidden):\n",
    "        embedded = self.embedding(inputs).view(1, -1, self.hidden_size)\n",
    "        embedded = F.relu(embedded)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = self.out(outputs)\n",
    "        #output = self.softmax(self.out(output[0]))\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch = 1\n",
    "inputs = torch.tensor([[1,2,3,4,5], [2,3,4,5,6]])\n",
    "embedding = nn.Embedding(40, 3)\n",
    "gru = nn.GRU(3, 3, batch_first=True)\n",
    "out = nn.Linear(3, 6)\n",
    "embedded = embedding(inputs)\n",
    "print(embedded.shape)\n",
    "embedded = F.relu(embedded)\n",
    "hidden = torch.zeros(1, 1, 3)\n",
    "outputs, hidden = gru(embedded, hidden)\n",
    "out(outputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for translation\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, device):\n",
    "        super(dataset, self).__init__()\n",
    "        self.data = pairs\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input, output = pairs[idx]\n",
    "        input_token = torch.tensor([input_lang.word2index[word] for word in input.split()] +\n",
    "                                   [EOS_token],\n",
    "                                   device=self.device)\n",
    "        output_token = torch.tensor([SOS_token] + \n",
    "                                    [output_lang.word2index[word] for word in output.split()] +\n",
    "                                    [EOS_token],\n",
    "                                    device=self.device)\n",
    "        return input_token, output_token\n",
    "    \n",
    "data = dataset(device)\n",
    "#dataloader = DataLoader(data,batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = torch.tensor([[[0,1,2],[3,4,5]]])\n",
    "print(decoder_outputs)\n",
    "print(decoder_outputs[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq():\n",
    "    def __init__(self, input_size, hidden_size, output_size, device):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.device = device\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, self.device).to(self.device)\n",
    "        self.decoder = DecoderRNN(hidden_size,output_size, self.device).to(self.device)\n",
    "    def train(self, dataset, epochs=5):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        encoder_optimizer = torch.optim.SGD(self.encoder.parameters(), lr=0.01)\n",
    "        decoder_optimizer = torch.optim.SGD(self.decoder.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for token_fra, token_eng in dataset:\n",
    "                # start running encoder\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "                \n",
    "                encoder_hidden = self.encoder.initHidden()\n",
    "                loss = 0\n",
    "                \n",
    "                encoder_outputs, encoder_hidden = self.encoder.forward(token_fra,encoder_hidden)\n",
    "\n",
    "                # encoder ouput is first hidden of decoder\n",
    "                decoder_hidden = encoder_hidden\n",
    "                # decoder_outputs shape: (B, seq lengths, hidden size)\n",
    "                decoder_outputs, decoder_hidden = self.decoder.forward(token_eng, decoder_hidden)\n",
    "                for index in range(len(token_eng)-1):\n",
    "                    loss += criterion(decoder_outputs[:,index,:], torch.tensor([token_eng[index+1]]))\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                loss.backward()\n",
    "                decoder_optimizer.step()\n",
    "                encoder_optimizer.step()\n",
    "            print(\"epoch:\", epoch, epoch_loss/len(dataset))\n",
    "    # data is a encoded sentence like nn.tensor([13,24,56,...])\n",
    "    def predict(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            encoder_hidden = self.encoder.initHidden()\n",
    "            loss = 0\n",
    "\n",
    "            encoder_outputs, encoder_hidden = self.encoder.forward(inputs\n",
    "                                                                ,encoder_hidden)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_output = None\n",
    "            eng_output = \"SOS\"\n",
    "            decoder_token = torch.tensor([SOS_token])\n",
    "    \n",
    "            while eng_output != \"EOS\":\n",
    "                decoder_output,decoder_hidden = self.decoder.forward(decoder_token, decoder_hidden)\n",
    "                decoder_token = torch.argmax(decoder_output)\n",
    "                eng_output = output_lang.index2word[int(decoder_token.numpy())]\n",
    "                print(eng_output)\n",
    "    def save(self, model_path):\n",
    "        encoder_path = model_path + \"_encoder\"\n",
    "        decoder_path = model_path + \"_decoder\"\n",
    "        torch.save(self.encoder.state_dict(), encoder_path)\n",
    "        torch.save(self.decoder.state_dict(), decoder_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.encoder.load_state_dict(torch.load(model_path + \"_encoder\"))\n",
    "        self.decoder.load_state_dict(torch.load(model_path + \"_decoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq(input_size=input_lang.n_words, hidden_size=5,output_size=output_lang.n_words, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 tensor(21.7806, grad_fn=<DivBackward0>)\n",
      "epoch: 1 tensor(20.9136, grad_fn=<DivBackward0>)\n",
      "epoch: 2 tensor(20.1201, grad_fn=<DivBackward0>)\n",
      "epoch: 3 tensor(19.6055, grad_fn=<DivBackward0>)\n",
      "epoch: 4 tensor(19.2604, grad_fn=<DivBackward0>)\n",
      "epoch: 5 tensor(19.0071, grad_fn=<DivBackward0>)\n",
      "epoch: 6 tensor(18.7740, grad_fn=<DivBackward0>)\n",
      "epoch: 7 tensor(18.5587, grad_fn=<DivBackward0>)\n",
      "epoch: 8 tensor(18.3767, grad_fn=<DivBackward0>)\n",
      "epoch: 9 tensor(18.2448, grad_fn=<DivBackward0>)\n",
      "epoch: 10 tensor(18.1581, grad_fn=<DivBackward0>)\n",
      "epoch: 11 tensor(17.9918, grad_fn=<DivBackward0>)\n",
      "epoch: 12 tensor(17.7965, grad_fn=<DivBackward0>)\n",
      "epoch: 13 tensor(17.7692, grad_fn=<DivBackward0>)\n",
      "epoch: 14 tensor(17.7204, grad_fn=<DivBackward0>)\n",
      "epoch: 15 tensor(17.6545, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.train(data,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "m\n",
      "the\n",
      "the\n",
      "you\n",
      ".\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "model = seq2seq(input_size=input_lang.n_words, hidden_size=5,output_size=output_lang.n_words, device=device)\n",
    "model.encoder.load_state_dict(torch.load(\"encoder_para\"))\n",
    "model.decoder.load_state_dict(torch.load(\"decoder_para\"))\n",
    "input_sentence = \"je suis mannequin\"\n",
    "input_token = torch.tensor([input_lang.word2index[word] for word in input_sentence.split()] +\n",
    "                                   [EOS_token],\n",
    "                                   device=device)\n",
    "model.predict(input_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # embedding of words\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        # attn combined with softmax output attention weights\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        # combine context c_i and input embedding y_{i-1}\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # concatenate embedded input and hidden of decoder to form the attention weights\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        # attention weights are then combined with encoder_output to form context vector\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        # embedded input and context vector are then concatenated and transformed\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        #\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(40, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
