{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq with batch training\n",
    "\n",
    "This notebook implementation of machine translation using seq2seq  where both encoder and decoder are LSTM. Batch training is enabled by padding input and output sentences. It's based on the [PyTorch tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "\n",
    "This part is taken from [PyTorch tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) with some modification\n",
    "\n",
    "data has been put under the folder /data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD is a token used to faciliate batch training when input sentences are not of uniform lengths.\n",
    "# SOS is start of sentence inserted in the beginning of the output sequence\n",
    "# EOS is end of sentence inserted at the end of both input and output sequences\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "# Language class consists of conversion from word to index and its inverse\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sentence from the data file\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only input sentence of length < 10 is used because this is a toy example\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4346\n",
      "eng 2804\n",
      "['il est gaucher .', 'he s a southpaw .']\n"
     ]
    }
   ],
   "source": [
    "# prepare training data from raw data\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model: encoder and decoder\n",
    "\n",
    "This part is taken from original PyTorch tutorial with some modification to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    # input shape: (B, largest seq length)\n",
    "    # input is padded\n",
    "    # hidden shape: (B, hidden_size)\n",
    "    # outputs shape: (B, sequence length, hidden_size)\n",
    "    def forward(self, inputs, hidden, batch_size=1, input_lengths=None):\n",
    "        embedded = self.embedding(inputs).view(batch_size, -1, self.hidden_size)\n",
    "        # in batch training, input sentences are of various lengths \n",
    "        if input_lengths:\n",
    "            outputs = pack_padded_sequence(embedded, input_lengths,\n",
    "                                            batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "            outputs, hidden = self.gru(outputs, hidden)\n",
    "            outputs, output_lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "            #outputs = outputs[np.arange(batch_size), output_lengths-1, :]\n",
    "           \n",
    "        # in prediction time, only one sentence is input\n",
    "        else:\n",
    "            outputs, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, device):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device=device\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # input shape: (B, largest seq length)\n",
    "    # input is padded\n",
    "    # embedded shape: (B, seq length, hidden size)\n",
    "    # outputs shape: (B, seq length, output size)\n",
    "    def forward(self, inputs, hidden, batch_size=1, input_lengths=None):\n",
    "        embedded = self.embedding(inputs).view(batch_size, -1, self.hidden_size)\n",
    "        embedded = F.relu(embedded)\n",
    "        # in batch training, input sentences are of various lengths\n",
    "        if input_lengths:\n",
    "            outputs = pack_padded_sequence(embedded, input_lengths,\n",
    "                                           batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "            \n",
    "            outputs, hidden = self.gru(outputs, hidden)\n",
    "            outputs, output_lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "        # in prediction\n",
    "        else:\n",
    "            outputs, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        outputs = self.out(outputs)\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator\n",
    "\n",
    "The original PyTorch tutorial does not contain this part for seq2seq. It skipped to seq2seq with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for translation\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_sequence_seq2seq(batch):\n",
    "    # output batch sentence pairs and length of each sentence in the batch\n",
    "    input_tokens = [pair[0] for pair in batch]\n",
    "    output_tokens = [pair[1] for pair in batch]\n",
    "    input_tokens_padded = pad_sequence(input_tokens, batch_first=True)\n",
    "    output_tokens_padded = pad_sequence(output_tokens, batch_first=True)\n",
    "    \n",
    "    input_lengths = [len(pair[0]) for pair in batch]\n",
    "    output_lengths = [len(pair[1]) for pair in batch]\n",
    "    \n",
    "    return input_tokens_padded, input_lengths, output_tokens_padded, output_lengths\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, device):\n",
    "        super(dataset, self).__init__()\n",
    "        self.data = pairs\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input, output = pairs[idx]\n",
    "        # add EOS and SOS\n",
    "        input_token = torch.tensor([input_lang.word2index[word] for word in input.split()] +\n",
    "                                   [EOS_token],\n",
    "                                   device=self.device)\n",
    "        output_token = torch.tensor([SOS_token] + \n",
    "                                    [output_lang.word2index[word] for word in output.split()] +\n",
    "                                    [EOS_token],\n",
    "                                    device=self.device)\n",
    "        return input_token, output_token\n",
    "    \n",
    "data = dataset(device)\n",
    "dataloader = DataLoader(data, collate_fn=pad_sequence_seq2seq ,batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq():\n",
    "    def __init__(self, input_size, hidden_size, output_size, device):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, self.device).to(self.device)\n",
    "        self.decoder = DecoderRNN(hidden_size,output_size, self.device).to(self.device)\n",
    "    def train(self, dataloader, epochs=5, encoder_lr=0.01, decoder_lr=0.01):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        encoder_optimizer = torch.optim.SGD(self.encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "        decoder_optimizer = torch.optim.SGD(self.decoder.parameters(), lr=0.01, momentum=0.9)\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for token_fra, token_fra_len, token_eng, token_eng_len in dataloader:\n",
    "                batch_size = token_fra.shape[0]\n",
    "                \n",
    "                # start running encoder\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "                loss = 0\n",
    "                \n",
    "                # init encoder hidden\n",
    "                encoder_hidden = self.encoder.initHidden(batch_size)\n",
    "                encoder_outputs, encoder_hidden = self.encoder.forward(token_fra,\n",
    "                                                      encoder_hidden,\n",
    "                                                    input_lengths=token_fra_len,\n",
    "                                                    batch_size=batch_size\n",
    "                                                    )\n",
    "                \n",
    "                # encoder ouput is first hidden of decoder\n",
    "                decoder_hidden = encoder_outputs[np.arange(batch_size), \n",
    "                                                 torch.tensor(token_fra_len)-1, :].view(1,batch_size,-1)\n",
    "                decoder_outputs, decoder_hidden = self.decoder.forward(token_eng,\n",
    "                                                                       decoder_hidden,\n",
    "                                                                       batch_size=batch_size,\n",
    "                                                                      input_lengths=token_eng_len)\n",
    "                for batch_index in range(batch_size):\n",
    "                    # decoder_outputs: (B, seq len, hidden size)\n",
    "                    output_length = token_eng_len[batch_index]\n",
    "                    loss += criterion(decoder_outputs[batch_index, 0:output_length-1, :],\n",
    "                                         token_eng[batch_index,1:output_length])\n",
    "                  \n",
    "                \n",
    "                epoch_loss += loss\n",
    "                loss.backward()\n",
    "                decoder_optimizer.step()\n",
    "                encoder_optimizer.step()\n",
    "            print(\"epoch:\", epoch, epoch_loss/len(dataloader))\n",
    "\n",
    "    def predict(model, inputs):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            encoder_hidden = model.encoder.initHidden(1)\n",
    "            loss = 0\n",
    "            encoder_outputs, encoder_hidden = model.encoder.forward(inputs,encoder_hidden)\n",
    "            decoder_hidden = encoder_outputs[:,-1,:].view(1,-1,7)\n",
    "            decoder_output = None\n",
    "            eng_output = \"SOS\"\n",
    "            decoder_token = torch.tensor([SOS_token], device=device)\n",
    "    \n",
    "            while eng_output != \"EOS\":\n",
    "            \n",
    "                decoder_output,decoder_hidden = model.decoder.forward(decoder_token,\n",
    "                                                                     decoder_hidden)\n",
    "                decoder_token = torch.argmax(decoder_output)\n",
    "                if device.type == 'cuda':\n",
    "                    eng_output = output_lang.index2word[int(decoder_token.cpu().numpy())]\n",
    "                else:\n",
    "                    eng_output = output_lang.index2word[int(decoder_token.numpy())]\n",
    "                print(eng_output)\n",
    "    def save(self, model_path):\n",
    "        encoder_path = model_path + \"_encoder\"\n",
    "        decoder_path = model_path + \"_decoder\"\n",
    "        torch.save(self.encoder.state_dict(), encoder_path)\n",
    "        torch.save(self.decoder.state_dict(), decoder_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.encoder.load_state_dict(torch.load(model_path + \"_encoder\"))\n",
    "        self.decoder.load_state_dict(torch.load(model_path + \"_decoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq(input_size=input_lang.n_words, hidden_size=7,output_size=output_lang.n_words, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 tensor(6.6274, grad_fn=<DivBackward0>)\n",
      "epoch: 1 tensor(5.7268, grad_fn=<DivBackward0>)\n",
      "epoch: 2 tensor(5.4315, grad_fn=<DivBackward0>)\n",
      "epoch: 3 tensor(5.2251, grad_fn=<DivBackward0>)\n",
      "496.23062896728516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.train(dataloader,epochs=4)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you\n",
      "re\n",
      "very\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      "the\n",
      ".\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "#model = seq2seq(input_size=input_lang.n_words, hidden_size=5,output_size=output_lang.n_words, device=device)\n",
    "#model.load(\"seq2seq\")\n",
    "input_sentence = \"tu es tres bon .\"\n",
    "input_token = torch.tensor([input_lang.word2index[word] for word in input_sentence.split()] +\n",
    "                                   [EOS_token],\n",
    "                                   device=device)\n",
    "#predict(model, input_token)\n",
    "model.predict(input_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
